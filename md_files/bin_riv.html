<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Behavioral Modeling of Binocular Rivalry</title>
</head>

<body>

    <img src="../images/mpi.jpg?raw=true" alt="MPI Image">

    <h1>Behavioral Modeling of Binocular Rivalry</h1>
    <h2>A long-sighted POMDP Model</h2>

    <h3>Project description:</h3>

    <h3>Introduction</h3>

    <h4>Reinforcement Learning - POMDPs</h4>

    <p>In the vast landscape of artificial intelligence, one domain stands out for its ability to mimic human learning and decision-making processes â€“ Reinforcement Learning (RL). At its core, RL is about training agents to make sequential decisions in an environment to maximize cumulative rewards. However, when faced with uncertainties and partial observability, Reinforcement Learning alone may fall short. This is where the intricacies of Partially Observable Markov Decision Processes (POMDPs) come into play.</p>

    <h3>Model</h3>

    <img src="../images/states.png?raw=true" alt="States Image">

    <h3>Methods</h3>

    <h3>Results</h3>

    <h3>Group</h3>

    <img src="../images/group.png?raw=true" alt="Group Image">

    <h3>References</h3>

</body>

</html>
